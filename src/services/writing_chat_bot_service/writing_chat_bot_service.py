import os
import requests
import json
import re
import uuid
import random
from typing import Dict, Optional, List

# LM Studio API endpoint (c√≥ th·ªÉ config qua env)
LM_STUDIO_BASE_URL = os.getenv('LM_STUDIO_URL', 'http://192.168.183.1:1234')
LM_STUDIO_API_URL = f"{LM_STUDIO_BASE_URL}/v1/chat/completions"

# Global session for reused connections (Speed optimization)
session = requests.Session()

# ============================================================================
# H∆Ø·ªöNG D·∫™N B·∫¨T GPU ƒê·ªÇ TƒÇNG T·ªêC ƒê·ªò (QUAN TR·ªåNG!)
# ============================================================================
# GPU nhanh h∆°n CPU 5-10 l·∫ßn. B·∫ÆT BU·ªòC b·∫≠t trong LM Studio:
#
# 1. M·ªü LM Studio
# 2. V√†o Settings ‚Üí Hardware
# 3. Ch·ªçn GPU Acceleration:
#    - NVIDIA: Ch·ªçn "CUDA" v√† set GPU Layers = Max (ho·∫∑c Auto)
#    - AMD: Ch·ªçn "ROCm" (n·∫øu h·ªó tr·ª£)
#    - Mac: Ch·ªçn "Metal" v√† set GPU Layers = Max
# 4. Ki·ªÉm tra log trong LM Studio:
#    - N·∫øu th·∫•y "Running on CPU" ‚Üí CH∆ØA b·∫≠t GPU
#    - N·∫øu th·∫•y "Using GPU" ho·∫∑c "CUDA" ‚Üí ƒê√£ b·∫≠t th√†nh c√¥ng
#
# 5. Model khuy·∫øn ngh·ªã cho GPU:
#    - NVIDIA GTX/RTX: D√πng model 7B-13B v·ªõi Q4
#    - NVIDIA RTX 3060+ (8GB+): C√≥ th·ªÉ d√πng 13B Q4
#    - NVIDIA RTX 4090: C√≥ th·ªÉ d√πng 20B+ Q4
#    - Model nh·∫π: phi-3-mini, qwen2.5-3b, llama-3.2-3b (Q4)
#
# 6. N·∫øu kh√¥ng c√≥ GPU ho·∫∑c GPU y·∫øu:
#    - D√πng model nh·ªè h∆°n (3B v·ªõi Q4)
#    - Gi·∫£m max_tokens trong code
#    - TƒÉng timeout
# ============================================================================

# Topic mapping v·ªõi m√¥ t·∫£ ti·∫øng Vi·ªát ƒë·ªÉ AI hi·ªÉu r√µ h∆°n
TOPIC_MAPPING = {
    # C∆° b·∫£n (General)
    "greetings": "Ch√†o h·ªèi v√† l√†m quen",
    "self_introduction": "Gi·ªõi thi·ªáu b·∫£n th√¢n",
    "daily_conversation": "Tr√≤ chuy·ªán h·∫±ng ng√†y",
    "weather_talk": "N√≥i v·ªÅ th·ªùi ti·∫øt",
    "family_friends": "Gia ƒë√¨nh v√† b·∫°n b√®",
    "weekend_plans": "K·∫ø ho·∫°ch cu·ªëi tu·∫ßn",
    # Trung b√¨nh (General)
    "shopping": "Mua s·∫Øm v√† thanh to√°n",
    "restaurant": "ƒê·∫∑t m√≥n v√† nh√† h√†ng",
    "transportation": "Ph∆∞∆°ng ti·ªán v√† di chuy·ªÉn",
    "asking_directions": "H·ªèi ƒë∆∞·ªùng v√† ch·ªâ ƒë∆∞·ªùng",
    "hotel_booking": "ƒê·∫∑t ph√≤ng kh√°ch s·∫°n",
    "doctor_visit": "Kh√°m b√°c sƒ© v√† s·ª©c kh·ªèe",
    "phone_calls": "Cu·ªôc g·ªçi ƒëi·ªán tho·∫°i",
    "making_friends": "K·∫øt b·∫°n v√† giao l∆∞u",
    "invitations": "M·ªùi v√† nh·∫≠n l·ªùi m·ªùi",
    "hobbies_sports": "S·ªü th√≠ch v√† th·ªÉ thao",
    "entertainment": "Gi·∫£i tr√≠ v√† phim ·∫£nh",
    "food_preferences": "S·ªü th√≠ch ·∫©m th·ª±c",
    "small_talk": "Tr√≤ chuy·ªán ph√≠m",
    # N√¢ng cao (General)
    "travel_planning": "L√™n k·∫ø ho·∫°ch du l·ªãch",
    "airport_customs": "S√¢n bay v√† h·∫£i quan",
    "emergencies": "T√¨nh hu·ªëng kh·∫©n c·∫•p",
    "expressing_opinions": "B√†y t·ªè √Ω ki·∫øn",
    "complaining_suggesting": "Ph√†n n√†n v√† g·ª£i √Ω",
    "cultural_differences": "Kh√°c bi·ªát vƒÉn h√≥a",
    "problem_solving": "Gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ",
    # Trung b√¨nh (IELTS)
    "university_life": "Cu·ªôc s·ªëng ƒë·∫°i h·ªçc",
    "study_methods": "Ph∆∞∆°ng ph√°p h·ªçc t·∫≠p",
    "online_learning": "H·ªçc tr·ª±c tuy·∫øn",
    "remote_work": "L√†m vi·ªác t·ª´ xa",
    "sustainable_living": "L·ªëi s·ªëng b·ªÅn v·ªØng",
    "healthy_lifestyle": "L·ªëi s·ªëng l√†nh m·∫°nh",
    "work_life_balance": "C√¢n b·∫±ng c√¥ng vi·ªác - cu·ªôc s·ªëng",
    "consumer_culture": "VƒÉn h√≥a ti√™u d√πng",
    "arts_education": "Gi√°o d·ª•c ngh·ªá thu·∫≠t",
    "tourism_impact": "T√°c ƒë·ªông du l·ªãch",
    # N√¢ng cao (IELTS)
    "education_system": "H·ªá th·ªëng gi√°o d·ª•c",
    "education_technology": "C√¥ng ngh·ªá trong gi√°o d·ª•c",
    "childhood_education": "Gi√°o d·ª•c tr·∫ª em",
    "higher_education": "Gi√°o d·ª•c ƒë·∫°i h·ªçc",
    "social_media_impact": "T√°c ƒë·ªông m·∫°ng x√£ h·ªôi",
    "artificial_intelligence": "Tr√≠ tu·ªá nh√¢n t·∫°o",
    "digital_privacy": "Quy·ªÅn ri√™ng t∆∞ s·ªë",
    "technology_addiction": "Nghi·ªán c√¥ng ngh·ªá",
    "automation_jobs": "T·ª± ƒë·ªông h√≥a v√† vi·ªác l√†m",
    "climate_change": "Bi·∫øn ƒë·ªïi kh√≠ h·∫≠u",
    "renewable_energy": "NƒÉng l∆∞·ª£ng t√°i t·∫°o",
    "pollution_solutions": "√î nhi·ªÖm v√† gi·∫£i ph√°p",
    "conservation_efforts": "N·ªó l·ª±c b·∫£o t·ªìn",
    "urban_planning": "Quy ho·∫°ch ƒë√¥ th·ªã",
    "mental_health": "S·ª©c kh·ªèe tinh th·∫ßn",
    "healthcare_systems": "H·ªá th·ªëng y t·∫ø",
    "aging_population": "D√¢n s·ªë gi√† h√≥a",
    "income_inequality": "B·∫•t b√¨nh ƒë·∫≥ng thu nh·∫≠p",
    "globalization": "To√†n c·∫ßu h√≥a",
    "traditional_vs_modern": "Truy·ªÅn th·ªëng vs hi·ªán ƒë·∫°i",
    "government_policies": "Ch√≠nh s√°ch ch√≠nh ph·ªß",
    "cultural_preservation": "B·∫£o t·ªìn vƒÉn h√≥a",
    "media_influence": "·∫¢nh h∆∞·ªüng c·ªßa truy·ªÅn th√¥ng",
    # Trung b√¨nh (C√¥ng vi·ªác)
    "job_interviews": "Ph·ªèng v·∫•n xin vi·ªác",
    "email_etiquette": "Nghi th·ª©c email",
    "team_collaboration": "H·ª£p t√°c nh√≥m",
    "career_planning": "L·∫≠p k·∫ø ho·∫°ch s·ª± nghi·ªáp",
    "skill_development": "Ph√°t tri·ªÉn k·ªπ nƒÉng",
    "workplace_learning": "H·ªçc t·∫≠p t·∫°i n∆°i l√†m vi·ªác",
    "professional_goals": "M·ª•c ti√™u ngh·ªÅ nghi·ªáp",
    # N√¢ng cao (C√¥ng vi·ªác)
    "networking_events": "S·ª± ki·ªán k·∫øt n·ªëi",
    "meeting_presentations": "H·ªçp v√† thuy·∫øt tr√¨nh",
    "performance_reviews": "ƒê√°nh gi√° hi·ªáu su·∫•t",
    "project_management": "Qu·∫£n l√Ω d·ª± √°n",
    "client_relations": "Quan h·ªá kh√°ch h√†ng",
    "negotiation_skills": "K·ªπ nƒÉng ƒë√†m ph√°n",
    "problem_solving_work": "Gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ c√¥ng vi·ªác",
    "leadership_styles": "Phong c√°ch l√£nh ƒë·∫°o",
    "employee_motivation": "ƒê·ªông l·ª±c nh√¢n vi√™n",
    "conflict_resolution": "Gi·∫£i quy·∫øt xung ƒë·ªôt",
    "change_management": "Qu·∫£n l√Ω thay ƒë·ªïi",
    "delegation_skills": "K·ªπ nƒÉng ph√¢n c√¥ng",
    "career_transitions": "Chuy·ªÉn ƒë·ªïi ngh·ªÅ nghi·ªáp",
    "tech_innovation": "ƒê·ªïi m·ªõi c√¥ng ngh·ªá",
    "financial_planning": "L·∫≠p k·∫ø ho·∫°ch t√†i ch√≠nh",
    "marketing_strategies": "Chi·∫øn l∆∞·ª£c marketing",
    "supply_chain": "Chu·ªói cung ·ª©ng",
    "quality_assurance": "ƒê·∫£m b·∫£o ch·∫•t l∆∞·ª£ng"
}

# Topic categories ƒë·ªÉ tr·∫£ v·ªÅ theo nh√≥m
TOPIC_CATEGORIES = {
    "general": {
        "üå± C∆° b·∫£n": [
            {"value": "greetings", "label": "Ch√†o h·ªèi v√† l√†m quen"},
            {"value": "self_introduction", "label": "Gi·ªõi thi·ªáu b·∫£n th√¢n"},
            {"value": "daily_conversation", "label": "Tr√≤ chuy·ªán h·∫±ng ng√†y"},
            {"value": "weather_talk", "label": "N√≥i v·ªÅ th·ªùi ti·∫øt"},
            {"value": "family_friends", "label": "Gia ƒë√¨nh v√† b·∫°n b√®"},
            {"value": "weekend_plans", "label": "K·∫ø ho·∫°ch cu·ªëi tu·∫ßn"}
        ],
        "üåø Trung b√¨nh": [
            {"value": "shopping", "label": "Mua s·∫Øm v√† thanh to√°n"},
            {"value": "restaurant", "label": "ƒê·∫∑t m√≥n v√† nh√† h√†ng"},
            {"value": "transportation", "label": "Ph∆∞∆°ng ti·ªán v√† di chuy·ªÉn"},
            {"value": "asking_directions", "label": "H·ªèi ƒë∆∞·ªùng v√† ch·ªâ ƒë∆∞·ªùng"},
            {"value": "hotel_booking", "label": "ƒê·∫∑t ph√≤ng kh√°ch s·∫°n"},
            {"value": "doctor_visit", "label": "Kh√°m b√°c sƒ© v√† s·ª©c kh·ªèe"},
            {"value": "phone_calls", "label": "Cu·ªôc g·ªçi ƒëi·ªán tho·∫°i"},
            {"value": "making_friends", "label": "K·∫øt b·∫°n v√† giao l∆∞u"},
            {"value": "invitations", "label": "M·ªùi v√† nh·∫≠n l·ªùi m·ªùi"},
            {"value": "hobbies_sports", "label": "S·ªü th√≠ch v√† th·ªÉ thao"},
            {"value": "entertainment", "label": "Gi·∫£i tr√≠ v√† phim ·∫£nh"},
            {"value": "food_preferences", "label": "S·ªü th√≠ch ·∫©m th·ª±c"},
            {"value": "small_talk", "label": "Tr√≤ chuy·ªán ph√≠m"}
        ],
        "üéØ N√¢ng cao": [
            {"value": "travel_planning", "label": "L√™n k·∫ø ho·∫°ch du l·ªãch"},
            {"value": "airport_customs", "label": "S√¢n bay v√† h·∫£i quan"},
            {"value": "emergencies", "label": "T√¨nh hu·ªëng kh·∫©n c·∫•p"},
            {"value": "expressing_opinions", "label": "B√†y t·ªè √Ω ki·∫øn"},
            {"value": "complaining_suggesting", "label": "Ph√†n n√†n v√† g·ª£i √Ω"},
            {"value": "cultural_differences", "label": "Kh√°c bi·ªát vƒÉn h√≥a"},
            {"value": "problem_solving", "label": "Gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ"}
        ]
    },
    "ielts": {
        "üåø Trung b√¨nh": [
            {"value": "university_life", "label": "Cu·ªôc s·ªëng ƒë·∫°i h·ªçc"},
            {"value": "study_methods", "label": "Ph∆∞∆°ng ph√°p h·ªçc t·∫≠p"},
            {"value": "online_learning", "label": "H·ªçc tr·ª±c tuy·∫øn"},
            {"value": "remote_work", "label": "L√†m vi·ªác t·ª´ xa"},
            {"value": "sustainable_living", "label": "L·ªëi s·ªëng b·ªÅn v·ªØng"},
            {"value": "healthy_lifestyle", "label": "L·ªëi s·ªëng l√†nh m·∫°nh"},
            {"value": "work_life_balance", "label": "C√¢n b·∫±ng c√¥ng vi·ªác - cu·ªôc s·ªëng"},
            {"value": "consumer_culture", "label": "VƒÉn h√≥a ti√™u d√πng"},
            {"value": "arts_education", "label": "Gi√°o d·ª•c ngh·ªá thu·∫≠t"},
            {"value": "tourism_impact", "label": "T√°c ƒë·ªông du l·ªãch"}
        ],
        "üéØ N√¢ng cao": [
            {"value": "education_system", "label": "H·ªá th·ªëng gi√°o d·ª•c"},
            {"value": "education_technology", "label": "C√¥ng ngh·ªá trong gi√°o d·ª•c"},
            {"value": "childhood_education", "label": "Gi√°o d·ª•c tr·∫ª em"},
            {"value": "higher_education", "label": "Gi√°o d·ª•c ƒë·∫°i h·ªçc"},
            {"value": "social_media_impact", "label": "T√°c ƒë·ªông m·∫°ng x√£ h·ªôi"},
            {"value": "artificial_intelligence", "label": "Tr√≠ tu·ªá nh√¢n t·∫°o"},
            {"value": "digital_privacy", "label": "Quy·ªÅn ri√™ng t∆∞ s·ªë"},
            {"value": "technology_addiction", "label": "Nghi·ªán c√¥ng ngh·ªá"},
            {"value": "automation_jobs", "label": "T·ª± ƒë·ªông h√≥a v√† vi·ªác l√†m"},
            {"value": "climate_change", "label": "Bi·∫øn ƒë·ªïi kh√≠ h·∫≠u"},
            {"value": "renewable_energy", "label": "NƒÉng l∆∞·ª£ng t√°i t·∫°o"},
            {"value": "pollution_solutions", "label": "√î nhi·ªÖm v√† gi·∫£i ph√°p"},
            {"value": "conservation_efforts", "label": "N·ªó l·ª±c b·∫£o t·ªìn"},
            {"value": "urban_planning", "label": "Quy ho·∫°ch ƒë√¥ th·ªã"},
            {"value": "mental_health", "label": "S·ª©c kh·ªèe tinh th·∫ßn"},
            {"value": "healthcare_systems", "label": "H·ªá th·ªëng y t·∫ø"},
            {"value": "aging_population", "label": "D√¢n s·ªë gi√† h√≥a"},
            {"value": "income_inequality", "label": "B·∫•t b√¨nh ƒë·∫≥ng thu nh·∫≠p"},
            {"value": "globalization", "label": "To√†n c·∫ßu h√≥a"},
            {"value": "traditional_vs_modern", "label": "Truy·ªÅn th·ªëng vs hi·ªán ƒë·∫°i"},
            {"value": "government_policies", "label": "Ch√≠nh s√°ch ch√≠nh ph·ªß"},
            {"value": "cultural_preservation", "label": "B·∫£o t·ªìn vƒÉn h√≥a"},
            {"value": "media_influence", "label": "·∫¢nh h∆∞·ªüng c·ªßa truy·ªÅn th√¥ng"}
        ]
    },
    "work": {
        "üåø Trung b√¨nh": [
            {"value": "job_interviews", "label": "Ph·ªèng v·∫•n xin vi·ªác"},
            {"value": "email_etiquette", "label": "Nghi th·ª©c email"},
            {"value": "team_collaboration", "label": "H·ª£p t√°c nh√≥m"},
            {"value": "career_planning", "label": "L·∫≠p k·∫ø ho·∫°ch s·ª± nghi·ªáp"},
            {"value": "skill_development", "label": "Ph√°t tri·ªÉn k·ªπ nƒÉng"},
            {"value": "workplace_learning", "label": "H·ªçc t·∫≠p t·∫°i n∆°i l√†m vi·ªác"},
            {"value": "professional_goals", "label": "M·ª•c ti√™u ngh·ªÅ nghi·ªáp"}
        ],
        "üéØ N√¢ng cao": [
            {"value": "networking_events", "label": "S·ª± ki·ªán k·∫øt n·ªëi"},
            {"value": "meeting_presentations", "label": "H·ªçp v√† thuy·∫øt tr√¨nh"},
            {"value": "performance_reviews", "label": "ƒê√°nh gi√° hi·ªáu su·∫•t"},
            {"value": "project_management", "label": "Qu·∫£n l√Ω d·ª± √°n"},
            {"value": "client_relations", "label": "Quan h·ªá kh√°ch h√†ng"},
            {"value": "negotiation_skills", "label": "K·ªπ nƒÉng ƒë√†m ph√°n"},
            {"value": "problem_solving_work", "label": "Gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ c√¥ng vi·ªác"},
            {"value": "leadership_styles", "label": "Phong c√°ch l√£nh ƒë·∫°o"},
            {"value": "employee_motivation", "label": "ƒê·ªông l·ª±c nh√¢n vi√™n"},
            {"value": "conflict_resolution", "label": "Gi·∫£i quy·∫øt xung ƒë·ªôt"},
            {"value": "change_management", "label": "Qu·∫£n l√Ω thay ƒë·ªïi"},
            {"value": "delegation_skills", "label": "K·ªπ nƒÉng ph√¢n c√¥ng"},
            {"value": "career_transitions", "label": "Chuy·ªÉn ƒë·ªïi ngh·ªÅ nghi·ªáp"},
            {"value": "tech_innovation", "label": "ƒê·ªïi m·ªõi c√¥ng ngh·ªá"},
            {"value": "financial_planning", "label": "L·∫≠p k·∫ø ho·∫°ch t√†i ch√≠nh"},
            {"value": "marketing_strategies", "label": "Chi·∫øn l∆∞·ª£c marketing"},
            {"value": "supply_chain", "label": "Chu·ªói cung ·ª©ng"},
            {"value": "quality_assurance", "label": "ƒê·∫£m b·∫£o ch·∫•t l∆∞·ª£ng"}
        ]
    }
}

def build_prompt(
    language: str,
    topic: str,
    difficulty: int,
    custom_topic: bool,
    custom_topic_text: str,
    content_type: str,
    learning_purpose: str
) -> str:
    """
    X√¢y d·ª±ng prompt t·ªëi ∆∞u ƒë·ªÉ g·ª≠i l√™n AI model.
    """
    # X√°c ƒë·ªãnh ng√¥n ng·ªØ target
    is_vietnamese = language.lower() in ['vietnamese', 'vi', 'ti·∫øng vi·ªát', 'tieng viet']
    
    # X√°c ƒë·ªãnh ch·ªß ƒë·ªÅ th·ª±c t·∫ø
    if custom_topic and custom_topic_text:
        actual_topic = custom_topic_text
    elif topic in TOPIC_MAPPING:
        # S·ª≠ d·ª•ng m√¥ t·∫£ ti·∫øng Vi·ªát t·ª´ mapping ƒë·ªÉ AI hi·ªÉu r√µ h∆°n
        actual_topic = TOPIC_MAPPING[topic]
    else:
        actual_topic = topic
    
    # Map difficulty level
    difficulty_map = {
        1: "beginner" if not is_vietnamese else "s∆° c·∫•p",
        2: "basic-intermediate" if not is_vietnamese else "c∆° b·∫£n-trung c·∫•p",
        3: "intermediate" if not is_vietnamese else "trung c·∫•p",
        4: "intermediate-advanced" if not is_vietnamese else "trung c·∫•p-cao c·∫•p",
        5: "advanced" if not is_vietnamese else "cao c·∫•p"
    }
    difficulty_text = difficulty_map.get(difficulty, difficulty_map[2])
    
    # Map content type
    content_type_map = {
        "DIALOGUE": "dialogue" if not is_vietnamese else "h·ªôi tho·∫°i",
        "ESSAY": "essay" if not is_vietnamese else "b√†i lu·∫≠n",
        "STORY": "story" if not is_vietnamese else "c√¢u chuy·ªán"
    }
    content_type_text = content_type_map.get(content_type, "dialogue")
    
    # Map learning purpose
    purpose_map = {
        "COMMUNICATION": "communication" if not is_vietnamese else "giao ti·∫øp",
        "GRAMMAR": "grammar" if not is_vietnamese else "ng·ªØ ph√°p",
        "VOCABULARY": "vocabulary" if not is_vietnamese else "t·ª´ v·ª±ng"
    }
    purpose_text = purpose_map.get(learning_purpose, "communication")
    
    # S·ªë l∆∞·ª£t h·ªôi tho·∫°i: T·ªëi thi·ªÉu 12, t·ªëi ƒëa 15 c√¢u
    # Random trong kho·∫£ng 12-15 ƒë·ªÉ c√≥ s·ª± ƒëa d·∫°ng
    turns_count = random.randint(12, 15)
    
    # T·ªêI ∆ØU PROMPT: Ng·∫Øn g·ªçn, r√µ r√†ng, y√™u c·∫ßu song ng·ªØ ƒë·ªÉ check ƒë√°p √°n
    # Y√äU C·∫¶U: C√¢u NG·∫ÆN G·ªåN, T·ª∞ NHI√äN nh∆∞ h·ªôi tho·∫°i th·ª±c t·∫ø (kh√¥ng qu√° d√†i)
    if is_vietnamese:
        prompt = f"""B·∫°n l√† tr·ª£ l√Ω ·∫£o t·∫°o n·ªôi dung h·ªçc t·∫≠p chuy√™n nghi·ªáp.
 Nhi·ªám v·ª•: T·∫°o {content_type_text} (t·ªëi thi·ªÉu 12, t·ªëi ƒëa {turns_count} l∆∞·ª£t) ƒë·ªÉ luy·ªán {language}.
 Ch·ªß ƒë·ªÅ: {actual_topic}
 Tr√¨nh ƒë·ªô: {difficulty_text} ({difficulty}/5) - M·ª•c ƒë√≠ch: {purpose_text}

 QUY ƒê·ªäNH B·∫ÆT BU·ªòC (KH√îNG ƒê∆Ø·ª¢C SAI):
 1. Format t·ª´ng d√≤ng: "T√™n: C√¢u Ti·∫øng Vi·ªát | D·ªãch Ti·∫øng Anh"
 2. KH√îNG ƒë√°nh s·ªë, KH√îNG d√≤ng tr·ªëng th·ª´a.
 3. S·ªë l∆∞·ª£ng: T·ªëi thi·ªÉu 12 c√¢u, t·ªëi ƒëa {turns_count} c√¢u (∆∞u ti√™n {turns_count} c√¢u).
 4. N·ªôi dung T·ª∞ NHI√äN, ƒê·ª¶ D√ÄI nh∆∞ h·ªôi tho·∫°i th·ª±c t·∫ø:
    - M·ªói c√¢u PH·∫¢I c√≥ √≠t nh·∫•t 15-20 t·ª´ (kh√¥ng t√≠nh t√™n ng∆∞·ªùi n√≥i)
    - C√¢u ƒë·∫ßy ƒë·ªß, chi ti·∫øt, c√≥ ng·ªØ c·∫£nh r√µ r√†ng, th√¥ng tin phong ph√∫
    - Th√™m chi ti·∫øt v·ªÅ t√¨nh hu·ªëng, l√Ω do, c·∫£m x√∫c ƒë·ªÉ c√¢u d√†i h∆°n
    - Gi·ªëng nh∆∞ ng∆∞·ªùi th·∫≠t n√≥i chuy·ªán v·ªõi nhau (kh√¥ng ph·∫£i c√¢u ng·∫Øn c·ª•t l·ªßn)
    - TR√ÅNH c√¢u qu√° ng·∫Øn (d∆∞·ªõi 15 t·ª´) - ƒë√¢y l√† l·ªói nghi√™m tr·ªçng
    - T·ª± nhi√™n, tho·∫£i m√°i, nh∆∞ng ph·∫£i ƒë·ªß d√†i v√† chi ti·∫øt
 5. Ph·∫£i c√≥ d·∫•u g·∫°ch ƒë·ª©ng "|" ph√¢n c√°ch.
 6. M·ªói l∆∞·ª£t h·ªôi tho·∫°i ph·∫£i c√≥ n·ªôi dung ph√π h·ª£p, kh√¥ng l·∫∑p l·∫°i.

 M·∫´u (c√¢u 15-20 t·ª´, T·ª∞ NHI√äN v√† ƒê·ª¶ D√ÄI):
 Lan: Ch√†o Minh, d·∫°o n√†y c√¥ng vi·ªác c·ªßa b·∫°n th·∫ø n√†o r·ªìi? M√¨nh th·∫•y b·∫°n b·∫≠n r·ªôn l·∫Øm. | Hello Minh, how has your work been lately? I noticed you've been very busy.
 Minh: ·ªîn c·∫£ Lan ·∫°, m√¨nh v·ª´a ƒë∆∞·ª£c giao m·ªôt d·ª± √°n m·ªõi li√™n quan ƒë·∫øn tr√≠ tu·ªá nh√¢n t·∫°o v√† ƒëang h·ªçc h·ªèi th√™m nhi·ªÅu ki·∫øn th·ª©c m·ªõi. | It's all good, Lan. I just got assigned a new project related to artificial intelligence and I'm learning a lot of new knowledge.
 Lan: ·ªí, nghe th√∫ v·ªã ƒë·∫•y! C·ª• th·ªÉ l√† d·ª± √°n g√¨ v·∫≠y b·∫°n? M√¨nh c≈©ng quan t√¢m ƒë·∫øn lƒ©nh v·ª±c n√†y. | Oh, that sounds interesting! What exactly is the project? I'm also interested in this field.

 B·∫ÆT ƒê·∫¶U NGAY - T·∫†O T·ªêI THI·ªÇU 12, T·ªêI ƒêA {turns_count} C√ÇU, M·ªñI C√ÇU PH·∫¢I C√ì √çT NH·∫§T 15-20 T·ª™:"""
    else:
        prompt = f"""You are a professional language learning content creator.
 Task: Create a {content_type_text} (minimum 12, maximum {turns_count} turns) for {language} practice.
 Topic: {actual_topic}
 Level: {difficulty_text} ({difficulty}/5) - Goal: {purpose_text}

 STRICT MANDATORY RULES:
 1. Format each line exactly as: "Speaker: Content in Vietnamese | Content in English"
 2. NO numbering, NO extra empty lines.
 3. Quantity: Minimum 12 sentences, maximum {turns_count} sentences (prefer {turns_count} sentences).
 4. Sentences MUST BE NATURAL, LONG ENOUGH, LIKE REAL CONVERSATIONS:
    - Each sentence MUST have at least 15-20 words (excluding speaker name)
    - Complete, detailed sentences with rich context and information
    - Add details about situations, reasons, emotions to make sentences longer
    - Like real people talking to each other (not short, abrupt sentences)
    - AVOID sentences that are too short (under 15 words) - this is a serious error
    - Natural, relaxed, but must be long enough and detailed
 5. MUST use vertical bar "|" as separator.
 6. Each turn must have appropriate content, no repetition.

 Example (15-20 words, NATURAL and LONG ENOUGH):
 Lan: Ch√†o Minh, d·∫°o n√†y c√¥ng vi·ªác c·ªßa b·∫°n th·∫ø n√†o r·ªìi? M√¨nh th·∫•y b·∫°n b·∫≠n r·ªôn l·∫Øm. | Hello Minh, how has your work been lately? I noticed you've been very busy.
 Minh: ·ªîn c·∫£ Lan ·∫°, m√¨nh v·ª´a ƒë∆∞·ª£c giao m·ªôt d·ª± √°n m·ªõi li√™n quan ƒë·∫øn tr√≠ tu·ªá nh√¢n t·∫°o v√† ƒëang h·ªçc h·ªèi th√™m nhi·ªÅu ki·∫øn th·ª©c m·ªõi. | It's all good, Lan. I just got assigned a new project related to artificial intelligence and I'm learning a lot of new knowledge.
 Lan: ·ªí, nghe th√∫ v·ªã ƒë·∫•y! C·ª• th·ªÉ l√† d·ª± √°n g√¨ v·∫≠y b·∫°n? M√¨nh c≈©ng quan t√¢m ƒë·∫øn lƒ©nh v·ª±c n√†y. | Oh, that sounds interesting! What exactly is the project? I'm also interested in this field.

 BEGIN IMMEDIATELY - CREATE MINIMUM 12, MAXIMUM {turns_count} SENTENCES, EACH MUST HAVE AT LEAST 15-20 WORDS:"""
    
    return prompt


def parse_dialogue_to_parallel_sentences(dialogue: str) -> tuple[List[str], List[str]]:
    """
    Parse dialogue song ng·ªØ th√†nh 2 m·∫£ng: Target v√† Native (Translation).
    Format: Speaker: Content | Translation
    """
    if not dialogue:
        return [], []
    
    target_sentences = []
    translation_sentences = []
    
    lines = dialogue.split('\n')
    
    for line in lines:
        line = line.strip()
        if not line:
            continue
        
        # Format chu·∫©n: "Speaker: Content | Translation"
        if '|' in line:
            parts = line.split('|')
            if len(parts) >= 2:
                target_part = parts[0].strip() # "Speaker: Content"
                trans_part = parts[1].strip()  # "Translation"
                
                # Logic x·ª≠ l√Ω n·∫øu AI l·ª° th√™m "Meaning:" hay "Translation:" v√†o ƒë·∫ßu
                # Ch·ªâ x·ª≠ l√Ω n·∫øu c√≥ prefix r√µ r√†ng (v√≠ d·ª• c√≥ d·∫•u :)
                if ':' in trans_part:
                    # N·∫øu format l√† "Meaning: Xin ch√†o" th√¨ b·ªè "Meaning:"
                    # N·∫øu format l√† "Speaker: Xin ch√†o" th√¨ c≈©ng c√≥ th·ªÉ b·ªè Speaker n·∫øu mu·ªën
                    # Nh∆∞ng ƒë·ªÉ an to√†n v√† ƒë∆°n gi·∫£n, ta gi·ªØ nguy√™n n·ªôi dung b·∫£n d·ªãch
                    # Tr·ª´ khi n√≥ qu√° d√†i d√≤ng.
                    # ·ªû ƒë√¢y ta ∆∞u ti√™n l·∫•y n·ªôi dung sau d·∫•u : cu·ªëi c√πng ho·∫∑c ƒë·∫ßu ti√™n?
                    # Prompt example: "A: Hello | Xin ch√†o" -> Kh√¥ng c√≥ :
                    pass

                target_sentences.append(target_part)
                
                # T·ª± ƒë·ªông th√™m Speaker cho ph·∫ßn Translation ƒë·ªÉ ng∆∞·ªùi d√πng bi·∫øt ai ƒëang n√≥i
                # target_part format: "Speaker: Content"
                if ':' in target_part:
                    speaker_name = target_part.split(':', 1)[0].strip()
                    # Ch·ªâ th√™m n·∫øu trans_part ch∆∞a c√≥ speaker ƒë√≥
                    if not trans_part.startswith(speaker_name):
                        trans_part = f"{speaker_name}: {trans_part}"
                
                translation_sentences.append(trans_part)
                
        elif ':' in line:
            # Fallback: c·ªë g·∫Øng c·ª©u d·ªØ li·ªáu n·∫øu thi·∫øu |
            target_sentences.append(line)
            # N·∫øu d√≤ng c√≥ format "A: Content", ta c·ª© coi nh∆∞ l√† Target
            # Translation ƒë·ªÉ tr·ªëng v√¨ kh√¥ng parse ƒë∆∞·ª£c
            translation_sentences.append("")
            
    return target_sentences, translation_sentences


def generate_dialogue(
    language: str,
    topic: str,
    difficulty: int,
    custom_topic: bool = False,
    custom_topic_text: str = "",
    content_type: str = "DIALOGUE",
    learning_purpose: str = "COMMUNICATION",
    mode: str = "AI_GENERATED"
) -> Dict:
    """
    G·ªçi LM Studio API ƒë·ªÉ t·∫°o dialogue/n·ªôi dung writing.
    """
    try:
        # X√¢y d·ª±ng prompt t·ªëi ∆∞u
        prompt = build_prompt(
            language=language,
            topic=topic,
            difficulty=difficulty,
            custom_topic=custom_topic,
            custom_topic_text=custom_topic_text,
            content_type=content_type,
            learning_purpose=learning_purpose
        )
        
        # T·ªëi ∆∞u token count - V·ªõi 12-15 c√¢u, m·ªói c√¢u 15-20 t·ª´ + translation
        # M·ªói c√¢u: 15-20 t·ª´ (VN) + 15-20 t·ª´ (EN) = ~30-40 t·ª´/c√¢u = ~45-60 tokens/c√¢u
        # T·ªïng: 15 c√¢u √ó 52 tokens = ~780 tokens, nh∆∞ng c·∫ßn buffer cho format
        max_tokens_map = {
            1: 1000,  # Beginner: 12-15 c√¢u d√†i (~800 tokens)
            2: 1100,  # Basic-intermediate: 12-15 c√¢u (~900 tokens)
            3: 1200,  # Intermediate: 12-15 c√¢u (~1000 tokens)
            4: 1300,  # Intermediate-advanced: 12-15 c√¢u (~1100 tokens)
            5: 1400   # Advanced: 12-15 c√¢u c√≥ th·ªÉ d√†i h∆°n m·ªôt ch√∫t (~1200 tokens)
        }
        max_tokens = max_tokens_map.get(difficulty, 1100)
        
        # OpenAI Configuration
        # L·∫•y API Key t·ª´ bi·∫øn m√¥i tr∆∞·ªùng (B·∫ÆT BU·ªòC)
        openai_api_key = os.getenv('OPENAI_API_KEY')
        if not openai_api_key:
             return {'error': 'OpenAI API Key is missing. Please set OPENAI_API_KEY env var.'}
             
        openai_api_url = "https://api.openai.com/v1/chat/completions"
        model_name = "gpt-3.5-turbo" # S·ª≠ d·ª•ng model nhanh & r·∫ª c·ªßa OpenAI
        
        # Payload chu·∫©n OpenAI
        payload = {
            "model": model_name,
            "messages": [
                {
                    "role": "system",
                    "content": "Format: 'Speaker: Content | Translation'."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.5,
            "max_tokens": max_tokens,
            "stream": False
        }
        
        # G·ªçi API OpenAI
        response = session.post(
            openai_api_url,
            json=payload,
            headers={
                "Content-Type": "application/json",
                "Authorization": f"Bearer {openai_api_key}"
            },
            timeout=60
        )
        
        if response.status_code != 200:
            return {'error': f'OpenAI API error: {response.status_code} - {response.text}'}
        
        result = response.json()
        
        if 'choices' in result and len(result['choices']) > 0:
            dialogue = result['choices'][0]['message']['content'].strip()
            
            # Parse th√†nh 2 list song song
            target_sents, trans_sents = parse_dialogue_to_parallel_sentences(dialogue)
            
            return {
                'dialogue': dialogue,
                'target_sentences': target_sents,
                'translation_sentences': trans_sents,
                'error': None
            }
        else:
            return {'error': 'Invalid response format'}
            
    except Exception as e:
        return {'error': f'Unexpected error: {str(e)}'}


def generate_suggestion(
    original_sentence: str,
    target_language: str = "English"
) -> Dict:
    """
    T·∫°o g·ª£i √Ω (hint) cho ng∆∞·ªùi d√πng khi h·ªç g·∫∑p kh√≥ khƒÉn.
    G·ª£i √Ω c√≥ th·ªÉ l√† t·ª´ v·ª±ng kh√≥, c·∫•u tr√∫c ng·ªØ ph√°p, ho·∫∑c g·ª£i √Ω d·ªãch nghƒ©a.
    """
    try:
        # Check API Key
        openai_api_key = os.getenv('OPENAI_API_KEY')
        if not openai_api_key:
             return {'error': 'OpenAI API Key is missing.'}
             
        openai_api_url = "https://api.openai.com/v1/chat/completions"
        model_name = "gpt-3.5-turbo"
        
        # X√°c ƒë·ªãnh ng√¥n ng·ªØ ngu·ªìn (source) v√† ƒë√≠ch (target)
        is_target_english = target_language.lower() in ['english', 'en']
        
        prompt = f"""You are a helpful language tutor.
Task: Analyze the following sentence and provide vocabulary hints and grammar structure for translation into {target_language}.

Input Sentence: "{original_sentence}"

REQUIREMENTS - Return ONLY valid JSON (no explanations, no markdown):
1. Extract 3-5 key vocabulary words/phrases from the sentence
2. For each word: provide the word in {target_language} and its meaning in Vietnamese
3. Describe the grammar structure used in the sentence (in Vietnamese)
4. Do NOT provide the full translation

JSON Format (MUST follow exactly):
{{
    "vocabulary": [
        {{"word": "word in {target_language}", "meaning": "nghƒ©a ti·∫øng Vi·ªát"}},
        {{"word": "another word", "meaning": "nghƒ©a kh√°c"}}
    ],
    "structure": "M√¥ t·∫£ c·∫•u tr√∫c ng·ªØ ph√°p b·∫±ng ti·∫øng Vi·ªát (v√≠ d·ª•: C√¢u h·ªèi tr·ª±c ti·∫øp, s·ª≠ d·ª•ng th√¨ hi·ªán t·∫°i ƒë∆°n...)"
}}

Return JSON only:"""

        payload = {
            "model": model_name,
            "messages": [
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            "temperature": 0.3,  # Gi·∫£m ƒë·ªÉ output nh·∫•t qu√°n h∆°n cho JSON
            "max_tokens": 300  # TƒÉng ƒë·ªÉ ƒë·ªß cho JSON response
        }
        
        # Use existing session
        response = session.post(
            openai_api_url,
            json=payload,
            headers={
                "Content-Type": "application/json",
                "Authorization": f"Bearer {openai_api_key}"
            },
            timeout=30
        )
        
        if response.status_code != 200:
             return {'error': f'OpenAI API error: {response.status_code}'}
             
        result = response.json()
        if 'choices' in result and len(result['choices']) > 0:
            content = result['choices'][0]['message']['content'].strip()
            
            # Parse JSON t·ª´ response
            try:
                # Lo·∫°i b·ªè markdown code blocks n·∫øu c√≥
                if content.startswith('```'):
                    # T√¨m v√† extract JSON t·ª´ code block
                    json_match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', content, re.DOTALL)
                    if json_match:
                        content = json_match.group(1)
                    else:
                        # N·∫øu kh√¥ng match, th·ª≠ l·∫•y ph·∫ßn gi·ªØa ```
                        content = re.sub(r'```[^`]*```', '', content, flags=re.DOTALL).strip()
                
                # Parse JSON
                suggestion_data = json.loads(content)
                
                # Validate structure
                if 'vocabulary' not in suggestion_data or 'structure' not in suggestion_data:
                    return {'error': 'Invalid response format: missing vocabulary or structure'}
                
                # Validate vocabulary format
                if not isinstance(suggestion_data['vocabulary'], list):
                    return {'error': 'Invalid response format: vocabulary must be an array'}
                
                # Validate each vocabulary item
                for item in suggestion_data['vocabulary']:
                    if not isinstance(item, dict) or 'word' not in item or 'meaning' not in item:
                        return {'error': 'Invalid response format: vocabulary items must have word and meaning'}
                
                return {
                    'vocabulary': suggestion_data['vocabulary'],
                    'structure': suggestion_data['structure'],
                    'error': None
                }
            except json.JSONDecodeError as e:
                # N·∫øu kh√¥ng parse ƒë∆∞·ª£c JSON, tr·∫£ v·ªÅ error
                return {'error': f'Failed to parse JSON response: {str(e)}. Raw content: {content[:200]}'}
        else:
            return {'error': 'No suggestion generated'}
            
    except requests.exceptions.Timeout:
        return {'error': 'Request timeout'}
    except requests.exceptions.ConnectionError:
        return {'error': 'Connection error: Check OpenAI API.'}
    except requests.exceptions.RequestException as e:
        return {'error': f'Request error: {str(e)}'}
    except Exception as e:
        return {'error': f'Unexpected error: {str(e)}'}


def get_topics(category: Optional[str] = None) -> Dict:
    """
    L·∫•y danh s√°ch topics theo category.
    
    Args:
        category: Category name (general, ielts, work) ho·∫∑c None ƒë·ªÉ l·∫•y t·∫•t c·∫£
    
    Returns:
        Dict v·ªõi danh s√°ch topics theo category
    """
    if category:
        category = category.lower()
        if category in TOPIC_CATEGORIES:
            return {
                'status': 'success',
                'category': category,
                'data': TOPIC_CATEGORIES[category]
            }
        else:
            return {
                'status': 'error',
                'message': f'Invalid category: {category}. Available: {", ".join(TOPIC_CATEGORIES.keys())}',
                'data': None
            }
    else:
        # Tr·∫£ v·ªÅ t·∫•t c·∫£ categories
        return {
            'status': 'success',
            'data': TOPIC_CATEGORIES
        }

